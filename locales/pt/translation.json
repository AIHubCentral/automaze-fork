{
    "general": {
        "translation_not_available": "Esse comando ainda n√£o est√° dispon√≠vel em portugu√™s.",
        "not_interaction_author": "Voc√™ n√£o iniciou essa intera√ß√£o. Use o comando para poder interagir."
    },
    "faq": {
        "topics": {
            "artifacting": "**Artefatos**: Quando o resultado da infer√™ncia soa rob√≥tica, distorcida, com ru√≠do de fundo e n√£o consegue produzir as palavras corretamente.",
            "architecture": "**Arquitetura do modelo**: Os principais modelos envolvidos no RVC s√£o HuBERT (para extra√ß√£o de recursos) e Net_G (o modelo gerador).",
            "batch size": "**Tamanho do lote**: Quantidade de GPU usada para treinar o modelo, tamanhos de lote maiores geralmente levam a uma dura√ß√£o de treinamento mais curta. Por outro lado, o tamanho menor do lote pode tornar o modelo mais preciso, no entanto, consome mais recursos e √© mais lento. **Para a maioria dos casos, um tamanho de lote de 4 d√° bons resultados**.",
            "epoch": "**√âpoca**: Se refere ao n√∫mero de itera√ß√µes executadas para concluir um ciclo completo do conjunto de dados (dataset) durante o treino. N√£o √© poss√≠vel dizer exatamente quantas √©pocas (epochs) voc√™ precisa para seu conjunto de dados, voc√™ precisa monitorar o [Gr√°fico do Tensorboard](https://docs.applio.org/getting-started/tensorboard) para saber se seu modelo est√° treinando demais (overtraining).",
            "dataset": "**Conjunto de dados (dataset)**: Refere-se a um conjunto de arquivos de √°udio compactados em um arquivo .zip, usado pelo RVC para treinamento do modelo de voz. Voc√™ pode aprender mais sobre o assunto na [Documenta√ß√£o do Applio](https://docs.applio.org/guides/create-datasets/create-datasets)",
            "G and D": "**G e D**: Refere-se aos modelos generativos (G) e discriminadores (D), respectivamente, que armazenam os dados de treinamento, com o modelo generativo aprendendo a replicar resultados semelhantes ao original e o discriminador tentando distinguir dados reais dos dados gerados.",
            "hubert": "HuBERT: √â um modelo baseado em transformer que extrai texto de um √°udio, previamente treinado em uma tarefa de previs√£o mascarada, que o RVC usa para treinar os modelos de voz. Existem v√°rios tipos de Hubert, alguns exemplos s√£o ContentVec, Hubert-Base japon√™s e Hubert-Large chin√™s. Voc√™ pode aprender mais sobre isso na [Documenta√ß√£o do Applio](https://docs.applio.org/faq)",
            "index": "**Integra√ß√£o Faiss (arquivo .index)**: A [biblioteca Faiss](https://github.com/facebookresearch/faiss) permite a pesquisa eficiente do vizinho mais pr√≥ximo (nearest neighbor) aproximado no RVC durante a infer√™ncia, recuperando e combinando segmentos de √°udio de treinamento com incorpora√ß√µes mais pr√≥ximas.",
            "model": "**Modelo**: O resultado do treinamento em um conjunto de dados. Os modelos RVC treinados geralmente t√™m a [extens√£o de arquivo .pth](https://medium.com/@manasnandmohan/comprehending-pth-files-the-backbone-of-pytorch-models-ef9b232e092a), que √© um formato de arquivo usado para salvar diferentes estados do modelo, incluindo pesos, desvios e outros par√¢metros. Verifique este [guia](https://docs.applio.org/getting-started/training) para aprender a fazer seu primeiro modelo de voz.",
            "net_g": "**Net_G**: O modelo gerador no RVC que usa recursos [HuBERT](https://arxiv.org/abs/2106.07447) e incorpora√ß√µes de 'speaker' como entrada para gerar a forma de onda de √°udio convertida.",
            "f0 extraction": "**M√©todos de extra√ß√£o F0**: T√©cnicas como Crepe (full-tiny), RMVPE e FCPE usadas para extrair informa√ß√µes de [frequ√™ncia fundamental (f0)](https://pt.wikipedia.org/wiki/Frequ%C3%AAncia_fundamental) do √°udio.",
            "pitch guidance": "**Orienta√ß√£o de tom**: Aproveita a [frequ√™ncia fundamental (f0)](https://pt.wikipedia.org/wiki/Frequ%C3%AAncia_fundamental) da voz de entrada durante a s√≠ntese (infer√™ncia) para melhor manter o tom, a entona√ß√£o e a melodia originais.",
            "sample rate": "üîâ **Taxa de amostragem** refere-se ao n√∫mero de vezes por segundo que um sinal de √°udio anal√≥gico √© convertido em digital, medido em Hertz (Hz). Taxas de amostragem mais altas capturam mais detalhes, mas aumentam o tamanho do arquivo. Simples, mas crucial para a qualidade do √°udio.\n\n> üí° **Dica**: Verifique a taxa de amostragem do seu conjunto de dados para escolher melhor um modelo pr√©-treinado, como 32k, 40k ou 48k. Infelizmente, ainda n√£o h√° nenhum pretrain de 44,1 Khz dispon√≠vel, ent√£o escolha um que tenha uma taxa de amostragem mais pr√≥xima do seu conjunto de dados e teste se funciona bem.",
            "inference": "**Infer√™ncia**: Processo em que um √°udio √© transformado pelo modelo de voz. Voc√™ pode aprender mais sobre isso na [Documenta√ß√£o do Applio](https://docs.applio.org/faq)",
            "overtraining": "**Overtraining**: Uma maneira eficaz de detectar o overtraining √© verificar se o [Gr√°fico do TensorBoard](https://docs.applio.org/getting-started/tensorboard) come√ßa a subir e nunca mais volta, levando a uma sa√≠da rob√≥tica e abafada com m√° articula√ß√£o.",
            "pretrain": "**Pretrained**: Um modelo treinado em v√°rios conjuntos de √°udios longos, usado como ponto de partida para o treino de modelos RVC. Voc√™ pode verificar uma boa lista de modelos pr√©-treinados em <#1233407331405004954>",
            "rmvpe": {
                "title": "Diferentes tipos de **RMVPE** para extra√ß√£o de altura (pitch)",
                "description": [
                    "- **rmvpe**: Um modelo robusto para estimativa de altura vocal em m√∫sica polif√¥nica, a vers√£o normal da melhor extra√ß√£o de altura, √© robusto e n√£o √© sens√≠vel ao ru√≠do",
                    "- **rmvpe+**: SOMENTE para Infer√™ncia, tem um limite de afina√ß√£o, limita a inclina√ß√£o m√°xima e m√≠nima poss√≠vel, basicamente excluindo valores de [f0](https://pt.wikipedia.org/wiki/Frequ%C3%AAncia_fundamental) abaixo e acima de certos limites",
                    "- **rmvpe-gpu**: SOMENTE para *Treinamento*, usa sua gpu para o processo de extra√ß√£o de recursos, usando mais gpu para tornar o treinamento mais r√°pido",
                    "- **rmvpe-onnx**: *Wokada* APENAS, √© obrigat√≥rio para usu√°rios AMD que usam modelos ONNX"
                ],
                "footer": "Cr√©ditos: Nick088"
            },
            "rvc": "**RVC (Retrieval-based Voice Conversion)**: Uma t√©cnica de clonagem de voz que recupera e combina segmentos de √°udio de um alto-falante de origem para sintetizar a voz de um alto-falante de destino, sem exigir grandes conjuntos de dados paralelos."
        },
        "unknown": {
            "message": "Sinto muito, {{user}}. N√£o encontrei o assunto que voc√™ estava procurando",
            "embedData": {
                "title": "Sugest√µes",
                "description": [
                    "Procure na [Documenta√ß√£o do AI HUB](https://docs.aihub.wtf/) ou do [Applio](https://docs.applio.org/faq). Voc√™ provavelmente vai achar sua resposta l√° üìö",
                    "Pe√ßa ajuda em {{okadaChannel}} se √© relacionado √† transforma√ß√£o de voz em tempo real",
                    "Pe√ßa ajuda em {{helpChannel}} para ajuda em geral, mas use o comando `!howtoask` primeiro para aprender estruturar sua pergunta adequadamente e aumentar sua chance de receber uma resposta",
                    "Por √∫ltimo, mas n√£o menos importante, pe√ßa ajuda em {{helpAiArtChannel}} se √© relacionado √† gera√ß√£o de imagens com IA"
                ]
            }
        }
    }
}