{
    "website": {
        "aihub": "https://docs.aihub.wtf/",
        "applio": "https://docs.applio.org/faq"
    },
    "faq": {
        "topics": {
            "artifacting": "**Artifacting**: When the inference output sounds robotic, distorted, with background noise, and fails to modulate words properly.",
            "architecture": "**Model Architecture**: The core models involved in RVC are HuBERT (for feature extraction) and Net_G (the generator model).",
            "batch size": "**Batch Size**: The amount of GPU used to train the model, with larger batch sizes generally leading to shorter training duration. On the other hand, lower batch size can make the model more accurate, however it's more resource intensive and slower. **For most cases a batch size of 4 gives good results**.",
            "epoch": "**Epoch**: The number of iterations performed to complete one full cycle of the dataset during training. It's not possible to say precisely how many epochs you need for your dataset, you need to monitor the [TensorBoard Graph](https://docs.applio.org/getting-started/tensorboard) to know if your model is overtraining.",
            "dataset": "Datasets are a set of audio files compressed into a .zip file, used by RVC for voice training. You can learn more about it in the [Applio Docs](https://docs.applio.org/guides/create-datasets/create-datasets)",
            "G and D": "**G and D**: Generative (G) and Discriminator (D) models, respectively, that store the training data, with the Generative model learning to replicate results similar to the original, and the Discriminator trying to distinguish real data from generated data.",
            "hubert": "**HuBERT**: A transformer-based model that extracts text from raw audio, previously trained on a masked prediction task, which RVC uses to train the voice models. There are several types of Hubert, some of examples are ContentVec, Japanese Hubert-Base and Chinese Hubert-Large. You can learn more about it in the [Applio Docs](https://docs.applio.org/faq)",
            "index": "**Faiss Integration (.index file)**: The [Faiss library](https://github.com/facebookresearch/faiss) enables efficient approximate nearest neighbor search in RVC during inference, retrieving and combining training audio segments with closest embeddings.",
            "model": "**Model**: The result of training on a dataset. Trained RVC models usually have the [.pth file extension](https://medium.com/@manasnandmohan/comprehending-pth-files-the-backbone-of-pytorch-models-ef9b232e092a) which is is a file format used to save different states of model including it's weights, biases and other parameter. Check this [guide](https://docs.applio.org/getting-started/training) for learning how to make your first voice model.",
            "net_g": "**Net_G**: The generator model in RVC that takes [HuBERT](https://arxiv.org/abs/2106.07447) features and speaker embeddings as input to generate the converted audio waveform.",
            "f0 extraction": "**F0 Extraction Methods**: Techniques like Crepe (full-tiny), RMVPE, and FCPE used for extracting fundamental frequency (pitch) information from audio.",
            "pitch guidance": "**Pitch Guidance**: Leveraging the [fundamental frequency (f0)](https://en.wikipedia.org/wiki/Fundamental_frequency) of the input voice during synthesis to better maintain the original pitch, intonation, and melody.",
            "sample rate": "ðŸ”‰ **Sample rate** refers to the number of times per second an analog audio signal is converted to digital, measured in Hertz (Hz). Higher sample rates capture more detail but increase file size. Simple yet crucial for audio quality.\n\n> ðŸ’¡ **Tip**: Check the sample rate of your dataset for better choosing a pretrained model such as 32k, 40k or 48k. Unfortunately there aren't any 44.1Khz pretrain available yet, so choose one that has a sample rate closer to your dataset and test if it works well.",
            "inference": "Inference is the process where an audio is transformed by the voice model. You can learn more about it in the [Applio Docs](https://docs.applio.org/faq)",
            "overtraining": "A solid way to detect overtraining is checking if the [TensorBoard Graph](https://docs.applio.org/getting-started/tensorboard) starts rising and never comes back down, leading to robotic, muffled output with poor articulation",
            "pretrain": "**Pretrained**: A model trained on several sets of long-duration audios, used as a starting point for training in RVC. You can check a good list of pretrained models in <#1233407331405004954>",
            "rvc": "**RVC (Retrieval-based Voice Conversion)**: A voice cloning technique that retrieves and combines audio segments from a source speaker to synthesize the voice of a target speaker, without requiring large parallel datasets."
        },
        "unknown": {
            "message": "I'm sorry, {{user}}. I couldn't find the topic you were looking for",
            "embedData": {
                "title": "You can try the following",
                "description": [
                    "Search for it in [AI HUB Docs](https://docs.aihub.wtf/) or [Applio Docs](https://docs.applio.org/faq). You will probably find your answer there ðŸ“š",
                    "Ask for help in {{okadaChannel}} if it's related to real time voice changing",
                    "Ask for help in {{helpChannel}} for general help, but use the command `!howtoask` first to learn how to structure your question properly and increase your chances of getting a reply",
                    "Last but not least, ask for help in {{helpAiArtChannel}} if it's related to AI images"
                ]
            }
        },
        "translation_not_available": "This command is not available in this language yet."
    }
}